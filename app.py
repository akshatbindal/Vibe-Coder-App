# --- START OF FILE app.py ---

import streamlit as st
import google.generativeai as genai
import os
from pathlib import Path
import json
import time
import requests # For calling the AWS API Gateway

# --- UI Components ---
from streamlit_option_menu import option_menu
from streamlit_ace import st_ace
import streamlit_antd_components as sac # Using for specific buttons

# --- Configuration ---
st.set_page_config(
    layout="wide",
    page_title="AI Lambda Code Generator"
)

# --- Constants ---
WORKSPACE_DIR = Path("workspace_lambda_handlers")
WORKSPACE_DIR.mkdir(exist_ok=True)

ACE_DEFAULT_THEME = "monokai"
ACE_DEFAULT_KEYBINDING = "vscode"

# Which Google AI model to use
GEMINI_MODEL_NAME = "gemini-1.5-flash" # Or your preferred Gemini model

# Instructions for the Google AI model for generating AWS Lambda handlers
GEMINI_SYSTEM_PROMPT = f"""
You are an AI assistant generating simple Python code snippets designed to run as AWS Lambda functions triggered by API Gateway.
Your goal is to create a Python script based on user requests that can handle an HTTP POST request and return HTML or JSON.

**Output Format:**
Respond *only* with the raw Python code for the Lambda function. Do NOT use markdown code fences (```python ... ```) or any explanatory text before or after the code.

**Code Requirements:**
1.  The Python code MUST define a function `generate_response(event_dict)`.
2.  This `generate_response` function receives the standard AWS API Gateway event dictionary (`event_dict`) as input. It can access request details like `event_dict.get('queryStringParameters')` or `event_dict.get('body')`.
3.  The `generate_response` function MUST return a Python dictionary with the following keys, formatted for API Gateway proxy integration:
    *   `'statusCode'`: An integer (e.g., 200, 400, 500).
    *   `'headers'`: A dictionary containing HTTP headers. MUST include `'Content-Type'` (e.g., `'text/html'` or `'application/json'`). Should include `'Access-Control-Allow-Origin': '*'` for compatibility.
    *   `'body'`: A string containing the response body (e.g., HTML content or a JSON string generated using `json.dumps()`).
4.  The code should be **stateless**. Do not rely on global variables holding state between invocations.
5.  Use only Python standard libraries available in the AWS Lambda Python runtime. **Do not import libraries like Flask, Streamlit, Pandas, etc.** unless specifically instructed AND acknowledging they might require Lambda layers. Keep it simple.
6.  Do not include the `lambda_handler` wrapper; only provide the code containing the `generate_response` function definition and any helper functions or imports it needs. The wrapper exists in the target Lambda environment.
7.  Handle potential errors gracefully within `generate_response` if possible (e.g., return statusCode 400 for bad input).

**Example Interaction:**

User: Create a simple HTML page that says "Hello World".

AI:
import json

def generate_response(event_dict):
    \"\"\"Generates a simple Hello World HTML page.\"\"\"
    html_content = \"\"\"
<!DOCTYPE html>
<html>
<head><title>Lambda Preview</title></head>
<body>
    <h1>Hello World from Lambda!</h1>
    <p>This page was generated by AI code running on AWS Lambda.</p>
</body>
</html>
\"\"\"
    return {{
        'statusCode': 200,
        'headers': {{
            'Content-Type': 'text/html',
            'Access-Control-Allow-Origin': '*'
        }},
        'body': html_content
    }}

User: Create a JSON endpoint that echoes back a query parameter named 'message'.

AI:
import json

def generate_response(event_dict):
    \"\"\"Echoes a query parameter named 'message'.\"\"\"
    query_params = event_dict.get('queryStringParameters', {{}})
    message = query_params.get('message', 'No message provided.')

    response_body = {{
        'received_message': message,
        'reply': f'Lambda received: {{message}}'
    }}

    return {{
        'statusCode': 200,
        'headers': {{
            'Content-Type': 'application/json',
            'Access-Control-Allow-Origin': '*'
        }},
        'body': json.dumps(response_body)
    }}

Ensure your entire response is *only* the raw Python code.
"""

# --- API Client Setup & Secrets ---
google_api_key = None
preview_api_endpoint_url = None
error_messages = []

try:
    google_api_key = st.secrets["my_secrets"]["gemini_api_key"]
    if not google_api_key:
        error_messages.append("üî¥ Google API Key not found in secrets.")
    else:
        genai.configure(api_key=google_api_key)
        model = genai.GenerativeModel(GEMINI_MODEL_NAME)
except KeyError:
     error_messages.append("üî¥ `my_secrets.gemini_api_key` not found in Streamlit secrets.")
except Exception as e:
    error_messages.append(f"üî¥ Failed to configure Google AI: {e}")

try:
    preview_api_endpoint_url = st.secrets["my_secrets"]["preview_api_endpoint"]
    if not preview_api_endpoint_url:
         error_messages.append("üî¥ AWS Preview API Endpoint URL not found in secrets.")
except KeyError:
     error_messages.append("üî¥ `my_secrets.preview_api_endpoint` not found in Streamlit secrets.")
except Exception as e:
     error_messages.append(f"üî¥ Failed to read Preview API Endpoint from secrets: {e}")

# Display critical errors and stop if necessary
if not google_api_key or not model:
     st.error("Critical Error: AI Model could not be initialized. Check Gemini API Key.")
     for msg in error_messages: st.error(msg)
     st.stop()
elif not preview_api_endpoint_url:
    st.warning("Warning: AWS Preview API Endpoint not configured. Preview functionality will be disabled.")
    # Don't stop, allow code generation/editing

# Display non-critical errors as warnings
for msg in error_messages:
    if "Preview API Endpoint" in msg and preview_api_endpoint_url is None: # Already handled above
         continue
    st.warning(msg)


# --- Session State ---
def initialize_session_state():
    """Sets up default values in Streamlit's session state dictionary."""
    state_defaults = {
        "messages": [],             # Chat history
        "selected_file": None,      # Filename in editor
        "file_content_on_load": "", # Content when file was loaded
        "preview_api_endpoint": preview_api_endpoint_url, # Store static endpoint URL
        "preview_html_content": None, # Store HTML/JSON result from Lambda
        "preview_error": None,      # Store error message from Lambda call
        "preview_requested_code": None, # Store code sent for the current preview
        "editor_unsaved_content": "", # Current text in editor
        "last_saved_content": "",   # Last successfully saved content
    }
    for key, default_value in state_defaults.items():
        if key not in st.session_state:
            st.session_state[key] = default_value

initialize_session_state()

# --- File System Functions ---
def get_workspace_python_files():
    """Gets a list of all '.py' filenames in the workspace directory."""
    if not WORKSPACE_DIR.is_dir():
        return []
    try:
        return sorted([
            f.name for f in WORKSPACE_DIR.iterdir() if f.is_file() and f.suffix == '.py'
        ])
    except Exception as e:
        st.error(f"Error reading workspace directory: {e}")
        return []

def read_file(filename):
    """Reads the text content of a file from the workspace."""
    if not filename or ".." in filename or filename.startswith(("/", "\\")):
        # st.error(f"Invalid file path: {filename}") # Less verbose
        return None
    filepath = WORKSPACE_DIR / filename
    try:
        with open(filepath, "r", encoding="utf-8") as f:
            return f.read()
    except FileNotFoundError:
        st.warning(f"File not found: {filename}")
        return None
    except Exception as e:
        st.error(f"Error reading file '{filename}': {e}")
        return None

def save_file(filename, content):
    """Writes text content to a file in the workspace."""
    if not filename or ".." in filename or filename.startswith(("/", "\\")):
        st.error(f"Invalid file path: {filename}")
        return False
    filepath = WORKSPACE_DIR / filename
    try:
        with open(filepath, "w", encoding="utf-8") as f:
            f.write(content)
        return True
    except Exception as e:
        st.error(f"Error saving file '{filename}': {e}")
        return False

def delete_file(filename):
    """Deletes a file from the workspace and updates app state."""
    if not filename or ".." in filename or filename.startswith(("/", "\\")):
        st.error(f"Invalid file path: {filename}")
        return False
    filepath = WORKSPACE_DIR / filename
    try:
        if filepath.is_file():
            os.remove(filepath)
            st.toast(f"Deleted: {filename}", icon="üóëÔ∏è")
            # If the deleted file was selected, clear selection
            if st.session_state.selected_file == filename:
                st.session_state.selected_file = None
                st.session_state.file_content_on_load = ""
                st.session_state.editor_unsaved_content = ""
                st.session_state.last_saved_content = ""
                # Also clear preview if it was for this file
                st.session_state.preview_html_content = None
                st.session_state.preview_error = None
                st.session_state.preview_requested_code = None
            return True
        else:
            st.warning(f"Could not delete: File '{filename}' not found.")
            return False
    except Exception as e:
        st.error(f"Error deleting file '{filename}': {e}")
        return False

# --- AI Interaction Functions ---
def ask_gemini_ai(chat_history, system_prompt):
    """Sends the conversation history to the Gemini AI and returns its response (raw code)."""
    # For this simpler interaction, we only need the last user message + system prompt
    last_user_message = ""
    if chat_history and chat_history[-1]["role"] == "user":
         last_user_message = chat_history[-1]["content"]
    else:
         return "# ERROR: No user message found to send to AI." # Should not happen with chat_input

    full_prompt = system_prompt + "\n\nUser request:\n" + last_user_message

    try:
        # print(f"DEBUG: Sending prompt:\n{full_prompt}") # Debugging
        response = model.generate_content(
            full_prompt,
            # Optional: Add safety settings if needed
            # safety_settings=[
            #     {"category": "HARM_CATEGORY_HARASSMENT", "threshold": "BLOCK_MEDIUM_AND_ABOVE"},
            #     # Add others as needed
            # ]
            )
        # print(f"DEBUG: Received response:\n{response.text}") # Debugging

        # --- Basic Cleaning of AI Response ---
        ai_code = response.text.strip()
        # Remove potential markdown fences if the AI didn't follow instructions
        if ai_code.startswith("```python"):
            ai_code = ai_code[9:]
            if ai_code.endswith("```"): ai_code = ai_code[:-3]
        elif ai_code.startswith("```"): # Generic fence
            ai_code = ai_code[3:]
            if ai_code.endswith("```"): ai_code = ai_code[:-3]

        return ai_code.strip() # Return the cleaned code string

    except Exception as e:
        error_message = f"Gemini API call failed: {type(e).__name__}"
        st.error(f"üî¥ {error_message}: {e}")
        # Try to extract more specific feedback if available (depends on library version)
        detailed_error = str(e)
        try: # Handle potential API response errors structure
            if response and response.prompt_feedback and response.prompt_feedback.block_reason:
                 detailed_error = f"Input blocked by safety filters ({response.prompt_feedback.block_reason})."
            elif response and response.candidates and response.candidates[0].finish_reason != 'STOP':
                  detailed_error = f"Response stopped ({response.candidates[0].finish_reason}). May be due to safety filters or length limits."
        except AttributeError: pass # Ignore if attributes don't exist
        except IndexError: pass # Ignore if candidates list is empty

        return f"# ERROR: AI generation failed.\n# {error_message}\n# {detailed_error[:300]}..."

# --- AWS Lambda Preview Function ---
def fetch_aws_preview(code_to_preview: str, api_endpoint: str):
    """Sends code to the AWS Lambda endpoint and returns the response content or error."""
    if not api_endpoint:
        return None, "Error: Preview API endpoint is not configured in secrets."

    headers = {'Content-Type': 'text/plain'} # Sending raw Python code string
    timeout = 28 # Seconds (API Gateway has 29s, Lambda default 3s, Lambda max 900s, keep it reasonable)

    try:
        # Make the POST request to the Lambda function via API Gateway
        response = requests.post(
            api_endpoint,
            data=code_to_preview.encode('utf-8'), # Send raw code string as bytes
            headers=headers,
            timeout=timeout
        )
        response.raise_for_status() # Raise HTTPError for bad responses (4xx or 5xx)

        # Determine how to display based on Content-Type
        content_type = response.headers.get('Content-Type', '').lower()
        if 'html' in content_type:
            return response.text, None # Return HTML content, no error
        elif 'json' in content_type:
            try:
                # Pretty-print JSON content inside a <pre> tag
                pretty_json = f"<pre>{json.dumps(response.json(), indent=2)}</pre>"
                return pretty_json, None
            except json.JSONDecodeError:
                 return f"<pre>{response.text}</pre>", None # Fallback to raw text if not valid JSON
        else:
             # Display other content types as plain text within <pre>
             return f"<pre>{response.text}</pre>", None

    except requests.exceptions.Timeout:
        error_msg = f"Error: Request timed out after {timeout} seconds."
        return None, error_msg
    except requests.exceptions.RequestException as e:
        status_code = getattr(e.response, 'status_code', 'N/A')
        error_msg = f"Error calling preview endpoint: {e}. Status Code: {status_code}"
        # Try to get error details from Lambda response body (expecting JSON error structure)
        lambda_error_details = ""
        try:
            if e.response is not None:
                lambda_error = e.response.json()
                lambda_error_details = f"Lambda Error: {lambda_error.get('error', 'Unknown')}"
                # Only include traceback if present and maybe not too long
                tb = lambda_error.get('traceback')
                if tb and isinstance(tb, list):
                     lambda_error_details += f"\nTraceback: ...{' '.join(tb[-3:])}" # Show last few lines
                elif tb:
                     lambda_error_details += f"\nTraceback: {str(tb)[:200]}..." # Show beginning if not list
        except Exception:
            # Fallback to raw response text if JSON parsing fails
            raw_response = getattr(e.response, 'text', 'N/A')[:500]
            lambda_error_details = f"Raw Response: {raw_response}"

        return None, f"{error_msg}\n{lambda_error_details}"
    except Exception as e: # Catch other unexpected errors
         error_msg = f"An unexpected error occurred during preview request: {e}"
         return None, error_msg

# --- Streamlit App UI ---

st.title("ü§ñ AI AWS Lambda Code Generator")

# --- Sidebar ---
with st.sidebar:
    st.header("üí¨ Chat & Controls")
    st.divider()

    # --- Chat History Display ---
    chat_container = st.container(height=400)
    with chat_container:
        if not st.session_state.messages:
            st.info("Chat history is empty. Describe the Lambda handler you want to generate.")
        else:
            for message in st.session_state.messages:
                role = message["role"]
                content = message["content"]
                avatar = "üßë‚Äçüíª" if role == "user" else "ü§ñ"

                with st.chat_message(role, avatar=avatar):
                    if role == "assistant" and isinstance(content, str):
                         # Display AI-generated code in a code block
                         st.code(content, language="python")
                    elif isinstance(content, str):
                        # Display user message or other text
                        st.write(content)
                    else:
                        st.write(f"Unexpected message format: {content}")

    # --- Chat Input Box ---
    user_prompt = st.chat_input("Describe the Lambda handler code...")
    if user_prompt:
        st.session_state.messages.append({"role": "user", "content": user_prompt})

        with st.spinner("üß† AI Generating Code..."):
            # Send request to AI (using the modified function)
            ai_generated_code = ask_gemini_ai(
                st.session_state.messages,
                GEMINI_SYSTEM_PROMPT
            )

        # Add AI response (code or error message) to chat history
        st.session_state.messages.append({"role": "assistant", "content": ai_generated_code})

        # --- Update Editor with Generated Code ---
                # --- Auto-Save Generated Code ---
                # --- Auto-Save or Auto-Create File ---
        if not ai_generated_code.startswith("# ERROR:"):
            selected_file = st.session_state.get("selected_file")
            new_file_created = False
            target_filename = selected_file

            # If no file is selected, create a new one
            if not target_filename:
                timestamp = time.strftime("%Y%m%d_%H%M%S")
                target_filename = f"handler_{timestamp}.py"
                st.info(f"No file selected. Creating new file: '{target_filename}'")
                new_file_created = True

            # Attempt to save the code to the target file (either existing or new)
            if save_file(target_filename, ai_generated_code):
                st.toast(f"AI code saved to '{target_filename}'.", icon="üíæ")
                # Update editor state to reflect the save
                st.session_state.file_content_on_load = ai_generated_code
                st.session_state.editor_unsaved_content = ai_generated_code
                st.session_state.last_saved_content = ai_generated_code

                # If a new file was created, update the selected file state
                if new_file_created:
                    st.session_state.selected_file = target_filename

                # Clear preview state as the saved content might be different
                st.session_state.preview_html_content = None
                st.session_state.preview_error = None
                st.session_state.preview_requested_code = None

            else:
                # save_file() already shows an error via st.error
                st.warning(f"AI code generated but failed to save to '{target_filename}'. Code is shown in chat.", icon="‚ö†Ô∏è")
                # If creation failed, ensure selected_file is not set to the failed name
                if new_file_created:
                     st.session_state.selected_file = None


        elif ai_generated_code:
            # Handle the case where AI returned an error message
             st.warning("AI generation resulted in an error. Code not saved.", icon="‚ùå")


        # Rerun to display the new message and update file list/editor state
        st.rerun()
    st.divider()

    # --- Status Info ---
    st.subheader("Status & Info")
    st.success(f"Using AI model: {GEMINI_MODEL_NAME}", icon="‚úÖ")
    st.warning(
        "**Notes:** AI generates Python code for AWS Lambda. Review code before saving. Preview executes code in AWS - ensure Lambda role has minimal permissions.",
    )
    if st.session_state.preview_api_endpoint:
        st.success("AWS Preview Endpoint Configured.", icon="‚òÅÔ∏è")
    else:
        st.error("AWS Preview Endpoint Missing in Secrets.", icon="‚ö†Ô∏è")

# --- Main Area Tabs ---
selected_tab = option_menu(
    menu_title=None,
    options=["Workspace", "Live Preview"],
    icons=["folder-fill", "play-btn-fill"],
    orientation="horizontal",
    key="main_tab_menu"
)

# --- Workspace Tab ---
if selected_tab == "Workspace":
    st.header("üìÇ Workspace & Editor")
    st.divider()

    file_list_col, editor_col = st.columns([0.3, 0.7])

    with file_list_col:
        st.subheader("Files")
        python_files = get_workspace_python_files()
        select_options = ["--- Select a file ---"] + python_files
        current_selection_in_state = st.session_state.get("selected_file")

        try:
            current_index = select_options.index(current_selection_in_state) if current_selection_in_state else 0
        except ValueError:
            current_index = 0

        selected_option = st.selectbox(
            "Edit file:", options=select_options, index=current_index,
            key="file_selector_dropdown", label_visibility="collapsed"
        )

        newly_selected_filename = selected_option if selected_option != "--- Select a file ---" else None
        if newly_selected_filename != current_selection_in_state:
            st.session_state.selected_file = newly_selected_filename
            file_content = read_file(newly_selected_filename) if newly_selected_filename else ""
            if file_content is None and newly_selected_filename:
                 file_content = f"# ERROR: Could not read file '{newly_selected_filename}'"

            st.session_state.file_content_on_load = file_content
            st.session_state.editor_unsaved_content = file_content
            st.session_state.last_saved_content = file_content
            # Clear preview when changing files
            st.session_state.preview_html_content = None
            st.session_state.preview_error = None
            st.session_state.preview_requested_code = None
            st.rerun()

    with editor_col:
        st.subheader("Code Editor")
        selected_filename = st.session_state.selected_file

        if selected_filename:
            st.caption(f"Editing: `{selected_filename}`")

            editor_current_text = st_ace(
                value=st.session_state.get('editor_unsaved_content', ''),
                language="python", theme=ACE_DEFAULT_THEME, keybinding=ACE_DEFAULT_KEYBINDING,
                font_size=14, tab_size=4, wrap=True, auto_update=False,
                key=f"ace_editor_{selected_filename}"
            )

            has_unsaved_changes = (editor_current_text != st.session_state.last_saved_content)

            if editor_current_text != st.session_state.editor_unsaved_content:
                st.session_state.editor_unsaved_content = editor_current_text
                st.rerun()

            editor_buttons = [
                sac.ButtonsItem(label="üíæ Save Changes", icon="save", disabled=not has_unsaved_changes),
                sac.ButtonsItem(label="üóëÔ∏è Delete File", icon="trash", color="red"),
            ]
            clicked_editor_button = sac.buttons(
                 items=editor_buttons, index=None, format_func='title',
                 align='end', size='small', return_index=False,
                 key="editor_action_buttons"
            )

            if clicked_editor_button == "üíæ Save Changes":
                if save_file(selected_filename, editor_current_text):
                    st.session_state.file_content_on_load = editor_current_text
                    st.session_state.last_saved_content = editor_current_text
                    st.toast(f"Saved: `{selected_filename}`", icon="üíæ")
                    time.sleep(0.5)
                    st.rerun()
                else:
                    st.error(f"Error: Could not save '{selected_filename}'.") # save_file shows error too

            elif clicked_editor_button == "üóëÔ∏è Delete File":
                 confirmed = sac.confirm_button(f"Delete `{selected_filename}`?", color="error")
                 if confirmed:
                      if delete_file(selected_filename):
                          st.rerun() # Deletion handles state updates

            if has_unsaved_changes:
                st.warning("You have unsaved changes.")

        else:
            st.info("Select a Python file from the list on the left to view or edit.")
            st_ace(value="# Select a file...", language="python", readonly=True, key="ace_placeholder")

# --- Live Preview Tab ---
elif selected_tab == "Live Preview":
    st.header("‚ñ∂Ô∏è AWS Lambda Preview")
    st.divider()
    st.warning("‚ö†Ô∏è Preview executes AI-generated code in an AWS Lambda environment. Ensure code is safe and the Lambda role has minimal permissions.")

    api_endpoint = st.session_state.get("preview_api_endpoint")
    selected_filename = st.session_state.get("selected_file")
    # Use the *saved* content for previewing
    code_to_preview = st.session_state.get("last_saved_content")

    st.subheader("Controls")
    if not api_endpoint:
        st.error("üî¥ Preview API Endpoint not configured. Set `preview_api_endpoint` in Streamlit secrets.")
    elif not selected_filename:
        st.info("Select a Python file in the 'Workspace' tab to enable preview.")
    elif code_to_preview is None or code_to_preview == "": # Check if saved content exists
        st.warning(f"File '{selected_filename}' is empty or has not been saved yet. Save some content to enable preview.")
    else:
        st.write(f"File selected for preview: `{selected_filename}`")
        # Button to trigger the preview
        if st.button(f"üöÄ Run Preview for {selected_filename}", type="primary", use_container_width=True):
            st.session_state.preview_html_content = None # Clear previous preview
            st.session_state.preview_error = None
            st.session_state.preview_requested_code = code_to_preview # Store code used

            with st.spinner("üöÄ Calling AWS Lambda endpoint..."):
                preview_content, error = fetch_aws_preview(code_to_preview, api_endpoint)
                if error:
                    st.session_state.preview_error = error
                else:
                    st.session_state.preview_html_content = preview_content
                st.rerun() # Rerun to show results/errors

    st.divider()

    # --- Preview Display Area ---
    st.subheader("Preview Window")
    last_preview_code = st.session_state.get("preview_requested_code")
    current_saved_code = st.session_state.get("last_saved_content")
    preview_error = st.session_state.get("preview_error")
    preview_content = st.session_state.get("preview_html_content")

    if preview_error:
        st.error("Preview Failed:")
        st.error(preview_error, icon="üî•") # Use st.error to display the error message
         # Optionally show the code that failed
        if last_preview_code:
              with st.expander("Show Code Sent to Lambda"):
                   st.code(last_preview_code, language="python")

    elif preview_content:
         st.success("Preview loaded successfully from AWS Lambda.", icon="‚úÖ")
         # Check if the code currently saved is different from what generated the preview
         if selected_filename and last_preview_code != current_saved_code:
              st.warning(f"Preview below is for the previously saved version of '{selected_filename}'. Save changes and run preview again for updates.", icon="‚ö†Ô∏è")

         # Display the HTML/JSON content returned from Lambda
         st.markdown("--- Preview Output ---")
         # Use a container with border for visual separation
         with st.container(border=True):
             st.markdown(preview_content, unsafe_allow_html=True)
         st.markdown("--- End Preview ---")

         # Optionally show the code that generated this preview
         # if last_preview_code:
         #      with st.expander("Show Code That Generated This Preview"):
         #           st.code(last_preview_code, language="python")
    else:
         st.info("Click 'Run Preview' on a selected and saved Python file to see the result here.")


# --- END OF FILE app.py ---